import os
import re
import json
import base64
import time
import sys
import requests
import google.generativeai as genai
import zipfile
import io
import traceback

# ==============================================================================
# I. C·∫§U H√åNH
# ==============================================================================
print("--- ü§ñ AI Auto-Debugger v1.0 Initializing ---")
try:
    ISSUE_BODY = os.environ.get("ISSUE_BODY", "") # L·∫•y t·ª´ trigger issue
    ISSUE_NUMBER = os.environ["ISSUE_NUMBER"]
    
    # L·∫•y t·ª´ trigger workflow_dispatch
    REPO_TO_FIX = os.environ.get("REPO_TO_FIX")
    FAILED_RUN_ID = os.environ.get("FAILED_RUN_ID")
    DEBUG_ATTEMPT = int(os.environ.get("DEBUG_ATTEMPT", 1))
    
    GEMINI_API_KEY = os.environ["GEMINI_API_KEY"]
    GITHUB_TOKEN = os.environ["GITHUB_TOKEN"]
    REPO_OWNER = os.environ["GH_USER"]
    COMMIT_EMAIL = os.environ["COMMIT_EMAIL"]
    COMMIT_NAME = os.environ["COMMIT_NAME"]
except (KeyError, ValueError) as e:
    print(f"‚ùå L·ªñI: Thi·∫øu bi·∫øn m√¥i tr∆∞·ªùng: {e}")
    sys.exit(1)

COMMIT_AUTHOR = {"name": COMMIT_NAME, "email": COMMIT_EMAIL}
API_BASE_URL = "https://api.github.com"
HEADERS = {"Authorization": f"Bearer {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3+json"}
genai.configure(api_key=GEMINI_API_KEY)
MAX_DEBUG_ATTEMPTS = 3

# ==============================================================================
# II. C√ÅC H√ÄM TI·ªÜN √çCH
# ==============================================================================
def post_issue_comment(message):
    url = f"{API_BASE_URL}/repos/{REPO_OWNER}/ai-factory/issues/{ISSUE_NUMBER}/comments"
    requests.post(url, headers=HEADERS, json={"body": message}, timeout=30)

def parse_bug_report(body):
    print("--- üïµÔ∏è  ƒêang ph√¢n t√≠ch b√°o c√°o l·ªói ---")
    repo_match = re.search(r"- \*\*Repo:\*\*\s*`(.+?)`", body)
    run_url_match = re.search(r"- \*\*Workflow Run URL:\*\*\s*(https\S+)", body)
    if not repo_match or not run_url_match:
        raise ValueError("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t Repo v√† Run URL t·ª´ b√°o c√°o l·ªói.")
    repo_name = repo_match.group(1)
    run_id = run_url_match.group(1).split('/')[-1]
    return repo_name, run_id

def get_failed_job_log(repo_name, run_id):
    print(f"--- üì• ƒêang t·∫£i log l·ªói t·ª´ Run ID: {run_id} ---")
    logs_url = f"{API_BASE_URL}/repos/{repo_name}/actions/runs/{run_id}/logs"
    for i in range(3): # Th·ª≠ l·∫°i 3 l·∫ßn
        response = requests.get(logs_url, headers=HEADERS, stream=True, timeout=60)
        if response.status_code == 200: break
        print(f"Log ch∆∞a s·∫µn s√†ng, ƒë·ª£i 10 gi√¢y... (l·∫ßn {i+1})")
        time.sleep(10)
    response.raise_for_status()
    with zipfile.ZipFile(io.BytesIO(response.content)) as z:
        log_file_name = next((name for name in z.namelist() if 'build' in name and name.endswith('.txt')), z.namelist()[0])
        with z.open(log_file_name) as f:
            log_content = f.read().decode('utf-8', errors='ignore')
    return "\n".join(log_content.splitlines()[-200:])

def get_file_content(repo_name, file_path):
    print(f"--- üìÑ ƒêang ƒë·ªçc n·ªôi dung file: {file_path} ---")
    try:
        url = f"{API_BASE_URL}/repos/{repo_name}/contents/{file_path}"
        response = requests.get(url, headers=HEADERS, timeout=30).json()
        return base64.b64decode(response['content']).decode('utf-8'), response['sha']
    except Exception: return None, None

def call_gemini_for_fix(error_log, files_content):
    print("--- üß† ƒêang g·ª≠i th√¥ng tin cho Gemini Pro ƒë·ªÉ ph√¢n t√≠ch v√† s·ª≠a l·ªói ---")
    context_files = "".join([f"\n\n--- Content of `{path}` ---\n```\n{content}\n```" for path, content in files_content.items() if content])
    debug_prompt = f"M·ªôt build Flutter ƒë√£ th·∫•t b·∫°i. Ph√¢n t√≠ch log v√† code ƒë·ªÉ s·ª≠a l·ªói.\n\n--- LOG L·ªñI ---\n```\n{error_log}\n```\n{context_files}\n\n**NHI·ªÜM V·ª§:**\n1. Ph√¢n t√≠ch nguy√™n nh√¢n.\n2. Vi·∫øt l·∫°i TO√ÄN B·ªò n·ªôi dung c·ªßa file c·∫ßn s·ª≠a.\n3. Tr·∫£ v·ªÅ M·ªòT JSON duy nh·∫•t c√≥ c·∫•u tr√∫c: `{{\"analysis\": \"...\", \"file_to_patch\": \"...\", \"corrected_code\": \"...\", \"commit_message\": \"...\"}}`. N·∫øu kh√¥ng s·ª≠a ƒë∆∞·ª£c, `file_to_patch` l√† `null`."
    model = genai.GenerativeModel("gemini-1.5-pro-latest")
    response = model.generate_content(debug_prompt, request_options={'timeout': 400})
    match = re.search(r'\{.*\}', response.text, re.DOTALL)
    if not match: raise ValueError(f"AI Debugger kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá.")
    return json.loads(match.group(0), strict=False)

def apply_patch(repo_name, file_path, new_content, commit_message, current_sha):
    print(f"--- ü©π ƒêang √°p d·ª•ng b·∫£n v√° cho file: {file_path} ---")
    url = f"{API_BASE_URL}/repos/{repo_name}/contents/{file_path}"
    data = {"message": commit_message, "content": base64.b64encode(new_content.encode('utf-8')).decode('utf-8'), "sha": current_sha, "author": COMMIT_AUTHOR}
    requests.put(url, headers=HEADERS, json=data).raise_for_status()
    print("   - ‚úÖ B·∫£n v√° ƒë√£ ƒë∆∞·ª£c commit!")

def re_trigger_fix(repo_to_fix, failed_run_id, next_attempt):
     print(f"--- üîÅ ƒêang k√≠ch ho·∫°t l·∫°i v√≤ng s·ª≠a l·ªói (l·∫ßn {next_attempt}) ---")
     url = f"{API_BASE_URL}/repos/{REPO_OWNER}/ai-factory/actions/workflows/auto_debugger.yml/dispatches"
     data = {'ref': 'main', 'inputs': {'failed_run_id': failed_run_id, 'repo_to_fix': repo_to_fix, 'debug_attempt': str(next_attempt)}}
     requests.post(url, headers=HEADERS, json=data).raise_for_status()
     
# ==============================================================================
# III. H√ÄM TH·ª∞C THI CH√çNH
# ==============================================================================
if __name__ == "__main__":
    try:
        repo_to_fix, failed_run_id = REPO_TO_FIX, FAILED_RUN_ID
        if not repo_to_fix or not failed_run_id: # L·∫•y t·ª´ issue n·∫øu trigger th·ªß c√¥ng b·ªã thi·∫øu
             repo_to_fix, failed_run_id = parse_bug_report(ISSUE_BODY)

        post_issue_comment(f"‚úÖ **AI Debugger ƒë√£ b·∫Øt ƒë·∫ßu l√†m vi·ªác** tr√™n repo `{repo_to_fix}` (L·∫ßn th·ª≠ #{DEBUG_ATTEMPT}).")
        
        if DEBUG_ATTEMPT > MAX_DEBUG_ATTEMPTS:
            post_issue_comment(f"üö® ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {MAX_DEBUG_ATTEMPTS} l·∫ßn s·ª≠a l·ªói. D·ª´ng l·∫°i.")
            sys.exit(1)
        
        log = get_failed_job_log(repo_to_fix, failed_run_id)
        
        files_to_read = ["pubspec.yaml", "lib/main.dart"]
        files_content_map = {path: get_file_content(repo_to_fix, path) for path in files_to_read}
            
        fix_suggestion = call_gemini_for_fix(log, {p: c[0] for p, c in files_content_map.items()})
        
        file_to_patch = fix_suggestion.get("file_to_patch")
        if file_to_patch and file_to_patch in files_content_map:
            current_sha = files_content_map[file_to_patch][1]
            if not current_sha: raise ValueError(f"Kh√¥ng t√¨m th·∫•y SHA c·ªßa file c·∫ßn v√°: {file_to_patch}")
            
            commit_message = f"{fix_suggestion['commit_message']} (AI Auto-Fix Attempt #{DEBUG_ATTEMPT})"
            apply_patch(repo_to_fix, file_to_patch, fix_suggestion["corrected_code"], commit_message, current_sha)
            
            post_issue_comment(f"üéâ **ƒê√£ √°p d·ª•ng b·∫£n v√° t·ª± ƒë·ªông (L·∫ßn #{DEBUG_ATTEMPT})!**\n\n- **Ph√¢n t√≠ch:** {fix_suggestion['analysis']}\n- **Commit:** `{commit_message}`\n\nM·ªôt build m·ªõi s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông k√≠ch ho·∫°t trong repo `{repo_to_fix}`.")
        else:
            post_issue_comment(f"**Ph√¢n t√≠ch c·ªßa AI:** {fix_suggestion.get('analysis', 'Kh√¥ng c√≥.')}\n\nAI cho r·∫±ng kh√¥ng th·ªÉ s·ª≠a l·ªói t·ª± ƒë·ªông. C·∫ßn s·ª± can thi·ªáp c·ªßa con ng∆∞·ªùi.")

    except Exception as e:
        error_trace = traceback.format_exc()
        error_message = f"‚ùå **[Debugger] ƒê√£ x·∫£y ra l·ªói:**\n\n**L·ªói:**\n```{e}```\n\n**Traceback:**\n```{error_trace}```"
        post_issue_comment(error_message)
        sys.exit(1)
